{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "import itertools as it\n",
    "import time\n",
    "import pylab as pl\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.a loss function `mean_absolute_error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(y_true, y_pred):\n",
    "    ''' your code here '''\n",
    "    if not isinstance(y_true,np.ndarray) and isinstance(y_pred, np.ndarray):\n",
    "        print(f\"Both inputs must be np-array.\")\n",
    "        \n",
    "    return sum(abs(y_true - y_pred)) / len(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b Cross-Validation function `cv`\n",
    "Inputs:\n",
    "- X: matrix\n",
    "- y: vertor\n",
    "- method: object\n",
    "- parameters: dictionary\n",
    "- loss_function: function\n",
    "- nfolds: int\n",
    "- nrepetitions: int\n",
    "\n",
    "Output: `method` object includs functions `fit(X, y)` and `predict(X)`\n",
    "- Output is a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisysincfunction(N, noise):\n",
    "    ''' noisysincfunction - generate data from the \"noisy sinc function\"\n",
    "        % usage\n",
    "        %     [X, Y] = noisysincfunction(N, noise)\n",
    "        %\n",
    "        % input\n",
    "        %     N: number of data points\n",
    "        %     noise: standard variation of the noise\n",
    "        %\n",
    "        % output\n",
    "        %     X: (1, N)-matrix uniformly sampled in -2pi, pi\n",
    "        %     Y: (1, N)-matrix equal to sinc(X) + noise\n",
    "        %\n",
    "        % description\n",
    "        %     Generates N points from the noisy sinc function\n",
    "        %\n",
    "        %        X ~ uniformly in [-2pi, pi]\n",
    "        %        Y = sinc(X) + eps, eps ~ Normal(0, noise.^2)\n",
    "        %\n",
    "        % author\n",
    "        %     Mikio Braun\n",
    "    '''\n",
    "    X = np.sort(2 * np.pi * np.random.rand(1, N) ) - np.pi\n",
    "    Y = np.sinc(X) + noise * np.random.randn(1, N)\n",
    "    return X.reshape(-1, 1), Y.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "TRAIN: [4 2 5 8 6 3] TEST: [7 0 1]\n",
      "Fold 2\n",
      "TRAIN: [7 0 1 8 6 3] TEST: [4 2 5]\n",
      "Fold 3\n",
      "TRAIN: [7 0 1 4 2 5] TEST: [8 6 3]\n"
     ]
    }
   ],
   "source": [
    "class KFold:\n",
    "    def __init__(self, n_splits=5):\n",
    "        self.n_splits = n_splits\n",
    "\n",
    "    def split(self, X):\n",
    "        n_samples = len(X)\n",
    "        indices = np.arange(n_samples)\n",
    "\n",
    "        rng = np.random.default_rng(True)\n",
    "        rng.shuffle(indices)\n",
    "        \n",
    "        fold_sizes = np.full(self.n_splits, n_samples // self.n_splits, dtype=int)\n",
    "        fold_sizes[:n_samples % self.n_splits] += 1\n",
    "        current = 0\n",
    "        splits = []\n",
    "        \n",
    "        for fold_size in fold_sizes:\n",
    "            start, stop = current, current + fold_size\n",
    "            test_idx = indices[start:stop]\n",
    "            train_idx = np.concatenate((indices[:start], indices[stop:]))\n",
    "            splits.append((train_idx, test_idx))\n",
    "            current = stop\n",
    "        \n",
    "        return splits\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "X = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "splits = kf.split(X)\n",
    "for i, (train_index, test_index) in enumerate(splits):\n",
    "    print(f\"Fold {i + 1}\")\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "def cv(X, y, method, parameters, loss_function=mean_absolute_error, nfolds=10, nrepetitions=5):\n",
    "    best_loss = float('inf')\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    kf = KFold(n_splits=nfolds)\n",
    "    \n",
    "    # all_param_combinations = list(itertools.product(*parameters.values()))\n",
    "    \n",
    "    all_param_combinations = np.array(list(itertools.product(parameters['alpha'], parameters['kernel'])))\n",
    "\n",
    "    for param_combination in all_param_combinations:\n",
    "        param_dict = dict(zip(['alpha', 'kernel'], param_combination))\n",
    "        param_dict['kernel_params'] = parameters['kernel_params']\n",
    "\n",
    "        total_loss = 0\n",
    "        \n",
    "        for _ in range(nrepetitions):\n",
    "            fold_losses = []\n",
    "            for train_index, val_index in kf.split(X):\n",
    "                X_train, X_val = X[train_index], X[val_index]\n",
    "                y_train, y_val = y[train_index], y[val_index]\n",
    "                \n",
    "                model = method(**param_dict)\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_val)\n",
    "                \n",
    "                fold_loss = loss_function(y_val, y_pred)\n",
    "                fold_losses.append(fold_loss)\n",
    "            \n",
    "            total_loss += np.mean(fold_losses)\n",
    "        \n",
    "        avg_loss = total_loss / nrepetitions\n",
    "        \n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            best_params = param_dict\n",
    "            best_model = method(**best_params)\n",
    "            best_model.fit(X, y)\n",
    "    \n",
    "    best_model.cvloss = best_loss\n",
    "    return best_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'alpha' parameter of KernelRidge must be a float in the range [0.0, inf) or an array-like. Got '0.01' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m Xte \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange( \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mpi, np\u001b[38;5;241m.\u001b[39mpi, \u001b[38;5;241m0.01\u001b[39m )\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m params \u001b[38;5;241m=\u001b[39m { \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel_params\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mlogspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m20\u001b[39m),\n\u001b[1;32m      7\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mlogspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m10\u001b[39m) }\n\u001b[0;32m----> 8\u001b[0m cvkrr \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKernelRidge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnrepetitions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m ypred \u001b[38;5;241m=\u001b[39m cvkrr\u001b[38;5;241m.\u001b[39mpredict(Xte)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRegularization range: 10**-4 .. 10**4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[106], line 28\u001b[0m, in \u001b[0;36mcv\u001b[0;34m(X, y, method, parameters, loss_function, nfolds, nrepetitions)\u001b[0m\n\u001b[1;32m     25\u001b[0m y_train, y_val \u001b[38;5;241m=\u001b[39m y[train_index], y[val_index]\n\u001b[1;32m     27\u001b[0m model \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparam_dict)\n\u001b[0;32m---> 28\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[1;32m     31\u001b[0m fold_loss \u001b[38;5;241m=\u001b[39m loss_function(y_val, y_pred)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/base.py:1145\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1140\u001b[0m partial_fit_and_fitted \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1141\u001b[0m     fit_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartial_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _is_fitted(estimator)\n\u001b[1;32m   1142\u001b[0m )\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[0;32m-> 1145\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/base.py:638\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    631\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \n\u001b[1;32m    633\u001b[0m \u001b[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;124;03m    accepted constraints.\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 638\u001b[0m     \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parameter_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:96\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m     )\n\u001b[0;32m---> 96\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'alpha' parameter of KernelRidge must be a float in the range [0.0, inf) or an array-like. Got '0.01' instead."
     ]
    }
   ],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "Xtr, Ytr = noisysincfunction(100, 0.1)\n",
    "Xte = np.arange( -np.pi, np.pi, 0.01 ).reshape(-1, 1)\n",
    "\n",
    "params = { 'kernel': ['linear'], 'kernel_params': np.logspace(-4,4,20),\n",
    "                'alpha': np.logspace(-2,2,10) }\n",
    "cvkrr = cv(Xtr, Ytr, KernelRidge, params, nrepetitions=2)\n",
    "ypred = cvkrr.predict(Xte)\n",
    "print('Regularization range: 10**-4 .. 10**4')\n",
    "print('Gaussian kernel parameter: ', cvkrr.kernelparameter)\n",
    "print('Regularization paramter: ', cvkrr.regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'gaussian', 'alpha': '0.01'}\n",
      "{'kernel': 'gaussian', 'alpha': '0.027825594022071243'}\n",
      "{'kernel': 'gaussian', 'alpha': '0.0774263682681127'}\n",
      "{'kernel': 'gaussian', 'alpha': '0.21544346900318834'}\n",
      "{'kernel': 'gaussian', 'alpha': '0.5994842503189409'}\n",
      "{'kernel': 'gaussian', 'alpha': '1.6681005372000592'}\n",
      "{'kernel': 'gaussian', 'alpha': '4.6415888336127775'}\n",
      "{'kernel': 'gaussian', 'alpha': '12.915496650148826'}\n",
      "{'kernel': 'gaussian', 'alpha': '35.93813663804626'}\n",
      "{'kernel': 'gaussian', 'alpha': '100.0'}\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "params = { 'kernel': ['gaussian'], 'kernelparameter': np.logspace(-4,4,20),\n",
    "        'alpha': np.logspace(-2,2,10) }\n",
    "\n",
    "all_param_combinations = np.array(list(itertools.product(params['kernel'], params['alpha'])))\n",
    "# all_param_combinations + params['kernelparameter']\n",
    "for param_combination in all_param_combinations:\n",
    "        param_dict = dict(zip(['kernel', 'alpha'], param_combination))\n",
    "        print(param_dict)\n",
    "        param_dict['kernelparameter'] = params['kernelparameter']\n",
    "        \n",
    "        total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gaussian', 0.0001, 0.01),\n",
       " ('gaussian', 0.0001, 0.027825594022071243),\n",
       " ('gaussian', 0.0001, 0.0774263682681127),\n",
       " ('gaussian', 0.0001, 0.21544346900318834),\n",
       " ('gaussian', 0.0001, 0.5994842503189409),\n",
       " ('gaussian', 0.0001, 1.6681005372000592),\n",
       " ('gaussian', 0.0001, 4.6415888336127775),\n",
       " ('gaussian', 0.0001, 12.915496650148826),\n",
       " ('gaussian', 0.0001, 35.93813663804626),\n",
       " ('gaussian', 0.0001, 100.0),\n",
       " ('gaussian', 0.00026366508987303583, 0.01),\n",
       " ('gaussian', 0.00026366508987303583, 0.027825594022071243),\n",
       " ('gaussian', 0.00026366508987303583, 0.0774263682681127),\n",
       " ('gaussian', 0.00026366508987303583, 0.21544346900318834),\n",
       " ('gaussian', 0.00026366508987303583, 0.5994842503189409),\n",
       " ('gaussian', 0.00026366508987303583, 1.6681005372000592),\n",
       " ('gaussian', 0.00026366508987303583, 4.6415888336127775),\n",
       " ('gaussian', 0.00026366508987303583, 12.915496650148826),\n",
       " ('gaussian', 0.00026366508987303583, 35.93813663804626),\n",
       " ('gaussian', 0.00026366508987303583, 100.0),\n",
       " ('gaussian', 0.0006951927961775605, 0.01),\n",
       " ('gaussian', 0.0006951927961775605, 0.027825594022071243),\n",
       " ('gaussian', 0.0006951927961775605, 0.0774263682681127),\n",
       " ('gaussian', 0.0006951927961775605, 0.21544346900318834),\n",
       " ('gaussian', 0.0006951927961775605, 0.5994842503189409),\n",
       " ('gaussian', 0.0006951927961775605, 1.6681005372000592),\n",
       " ('gaussian', 0.0006951927961775605, 4.6415888336127775),\n",
       " ('gaussian', 0.0006951927961775605, 12.915496650148826),\n",
       " ('gaussian', 0.0006951927961775605, 35.93813663804626),\n",
       " ('gaussian', 0.0006951927961775605, 100.0),\n",
       " ('gaussian', 0.0018329807108324356, 0.01),\n",
       " ('gaussian', 0.0018329807108324356, 0.027825594022071243),\n",
       " ('gaussian', 0.0018329807108324356, 0.0774263682681127),\n",
       " ('gaussian', 0.0018329807108324356, 0.21544346900318834),\n",
       " ('gaussian', 0.0018329807108324356, 0.5994842503189409),\n",
       " ('gaussian', 0.0018329807108324356, 1.6681005372000592),\n",
       " ('gaussian', 0.0018329807108324356, 4.6415888336127775),\n",
       " ('gaussian', 0.0018329807108324356, 12.915496650148826),\n",
       " ('gaussian', 0.0018329807108324356, 35.93813663804626),\n",
       " ('gaussian', 0.0018329807108324356, 100.0),\n",
       " ('gaussian', 0.004832930238571752, 0.01),\n",
       " ('gaussian', 0.004832930238571752, 0.027825594022071243),\n",
       " ('gaussian', 0.004832930238571752, 0.0774263682681127),\n",
       " ('gaussian', 0.004832930238571752, 0.21544346900318834),\n",
       " ('gaussian', 0.004832930238571752, 0.5994842503189409),\n",
       " ('gaussian', 0.004832930238571752, 1.6681005372000592),\n",
       " ('gaussian', 0.004832930238571752, 4.6415888336127775),\n",
       " ('gaussian', 0.004832930238571752, 12.915496650148826),\n",
       " ('gaussian', 0.004832930238571752, 35.93813663804626),\n",
       " ('gaussian', 0.004832930238571752, 100.0),\n",
       " ('gaussian', 0.012742749857031334, 0.01),\n",
       " ('gaussian', 0.012742749857031334, 0.027825594022071243),\n",
       " ('gaussian', 0.012742749857031334, 0.0774263682681127),\n",
       " ('gaussian', 0.012742749857031334, 0.21544346900318834),\n",
       " ('gaussian', 0.012742749857031334, 0.5994842503189409),\n",
       " ('gaussian', 0.012742749857031334, 1.6681005372000592),\n",
       " ('gaussian', 0.012742749857031334, 4.6415888336127775),\n",
       " ('gaussian', 0.012742749857031334, 12.915496650148826),\n",
       " ('gaussian', 0.012742749857031334, 35.93813663804626),\n",
       " ('gaussian', 0.012742749857031334, 100.0),\n",
       " ('gaussian', 0.03359818286283781, 0.01),\n",
       " ('gaussian', 0.03359818286283781, 0.027825594022071243),\n",
       " ('gaussian', 0.03359818286283781, 0.0774263682681127),\n",
       " ('gaussian', 0.03359818286283781, 0.21544346900318834),\n",
       " ('gaussian', 0.03359818286283781, 0.5994842503189409),\n",
       " ('gaussian', 0.03359818286283781, 1.6681005372000592),\n",
       " ('gaussian', 0.03359818286283781, 4.6415888336127775),\n",
       " ('gaussian', 0.03359818286283781, 12.915496650148826),\n",
       " ('gaussian', 0.03359818286283781, 35.93813663804626),\n",
       " ('gaussian', 0.03359818286283781, 100.0),\n",
       " ('gaussian', 0.08858667904100823, 0.01),\n",
       " ('gaussian', 0.08858667904100823, 0.027825594022071243),\n",
       " ('gaussian', 0.08858667904100823, 0.0774263682681127),\n",
       " ('gaussian', 0.08858667904100823, 0.21544346900318834),\n",
       " ('gaussian', 0.08858667904100823, 0.5994842503189409),\n",
       " ('gaussian', 0.08858667904100823, 1.6681005372000592),\n",
       " ('gaussian', 0.08858667904100823, 4.6415888336127775),\n",
       " ('gaussian', 0.08858667904100823, 12.915496650148826),\n",
       " ('gaussian', 0.08858667904100823, 35.93813663804626),\n",
       " ('gaussian', 0.08858667904100823, 100.0),\n",
       " ('gaussian', 0.23357214690901212, 0.01),\n",
       " ('gaussian', 0.23357214690901212, 0.027825594022071243),\n",
       " ('gaussian', 0.23357214690901212, 0.0774263682681127),\n",
       " ('gaussian', 0.23357214690901212, 0.21544346900318834),\n",
       " ('gaussian', 0.23357214690901212, 0.5994842503189409),\n",
       " ('gaussian', 0.23357214690901212, 1.6681005372000592),\n",
       " ('gaussian', 0.23357214690901212, 4.6415888336127775),\n",
       " ('gaussian', 0.23357214690901212, 12.915496650148826),\n",
       " ('gaussian', 0.23357214690901212, 35.93813663804626),\n",
       " ('gaussian', 0.23357214690901212, 100.0),\n",
       " ('gaussian', 0.615848211066026, 0.01),\n",
       " ('gaussian', 0.615848211066026, 0.027825594022071243),\n",
       " ('gaussian', 0.615848211066026, 0.0774263682681127),\n",
       " ('gaussian', 0.615848211066026, 0.21544346900318834),\n",
       " ('gaussian', 0.615848211066026, 0.5994842503189409),\n",
       " ('gaussian', 0.615848211066026, 1.6681005372000592),\n",
       " ('gaussian', 0.615848211066026, 4.6415888336127775),\n",
       " ('gaussian', 0.615848211066026, 12.915496650148826),\n",
       " ('gaussian', 0.615848211066026, 35.93813663804626),\n",
       " ('gaussian', 0.615848211066026, 100.0),\n",
       " ('gaussian', 1.623776739188721, 0.01),\n",
       " ('gaussian', 1.623776739188721, 0.027825594022071243),\n",
       " ('gaussian', 1.623776739188721, 0.0774263682681127),\n",
       " ('gaussian', 1.623776739188721, 0.21544346900318834),\n",
       " ('gaussian', 1.623776739188721, 0.5994842503189409),\n",
       " ('gaussian', 1.623776739188721, 1.6681005372000592),\n",
       " ('gaussian', 1.623776739188721, 4.6415888336127775),\n",
       " ('gaussian', 1.623776739188721, 12.915496650148826),\n",
       " ('gaussian', 1.623776739188721, 35.93813663804626),\n",
       " ('gaussian', 1.623776739188721, 100.0),\n",
       " ('gaussian', 4.281332398719396, 0.01),\n",
       " ('gaussian', 4.281332398719396, 0.027825594022071243),\n",
       " ('gaussian', 4.281332398719396, 0.0774263682681127),\n",
       " ('gaussian', 4.281332398719396, 0.21544346900318834),\n",
       " ('gaussian', 4.281332398719396, 0.5994842503189409),\n",
       " ('gaussian', 4.281332398719396, 1.6681005372000592),\n",
       " ('gaussian', 4.281332398719396, 4.6415888336127775),\n",
       " ('gaussian', 4.281332398719396, 12.915496650148826),\n",
       " ('gaussian', 4.281332398719396, 35.93813663804626),\n",
       " ('gaussian', 4.281332398719396, 100.0),\n",
       " ('gaussian', 11.288378916846883, 0.01),\n",
       " ('gaussian', 11.288378916846883, 0.027825594022071243),\n",
       " ('gaussian', 11.288378916846883, 0.0774263682681127),\n",
       " ('gaussian', 11.288378916846883, 0.21544346900318834),\n",
       " ('gaussian', 11.288378916846883, 0.5994842503189409),\n",
       " ('gaussian', 11.288378916846883, 1.6681005372000592),\n",
       " ('gaussian', 11.288378916846883, 4.6415888336127775),\n",
       " ('gaussian', 11.288378916846883, 12.915496650148826),\n",
       " ('gaussian', 11.288378916846883, 35.93813663804626),\n",
       " ('gaussian', 11.288378916846883, 100.0),\n",
       " ('gaussian', 29.763514416313132, 0.01),\n",
       " ('gaussian', 29.763514416313132, 0.027825594022071243),\n",
       " ('gaussian', 29.763514416313132, 0.0774263682681127),\n",
       " ('gaussian', 29.763514416313132, 0.21544346900318834),\n",
       " ('gaussian', 29.763514416313132, 0.5994842503189409),\n",
       " ('gaussian', 29.763514416313132, 1.6681005372000592),\n",
       " ('gaussian', 29.763514416313132, 4.6415888336127775),\n",
       " ('gaussian', 29.763514416313132, 12.915496650148826),\n",
       " ('gaussian', 29.763514416313132, 35.93813663804626),\n",
       " ('gaussian', 29.763514416313132, 100.0),\n",
       " ('gaussian', 78.47599703514607, 0.01),\n",
       " ('gaussian', 78.47599703514607, 0.027825594022071243),\n",
       " ('gaussian', 78.47599703514607, 0.0774263682681127),\n",
       " ('gaussian', 78.47599703514607, 0.21544346900318834),\n",
       " ('gaussian', 78.47599703514607, 0.5994842503189409),\n",
       " ('gaussian', 78.47599703514607, 1.6681005372000592),\n",
       " ('gaussian', 78.47599703514607, 4.6415888336127775),\n",
       " ('gaussian', 78.47599703514607, 12.915496650148826),\n",
       " ('gaussian', 78.47599703514607, 35.93813663804626),\n",
       " ('gaussian', 78.47599703514607, 100.0),\n",
       " ('gaussian', 206.913808111479, 0.01),\n",
       " ('gaussian', 206.913808111479, 0.027825594022071243),\n",
       " ('gaussian', 206.913808111479, 0.0774263682681127),\n",
       " ('gaussian', 206.913808111479, 0.21544346900318834),\n",
       " ('gaussian', 206.913808111479, 0.5994842503189409),\n",
       " ('gaussian', 206.913808111479, 1.6681005372000592),\n",
       " ('gaussian', 206.913808111479, 4.6415888336127775),\n",
       " ('gaussian', 206.913808111479, 12.915496650148826),\n",
       " ('gaussian', 206.913808111479, 35.93813663804626),\n",
       " ('gaussian', 206.913808111479, 100.0),\n",
       " ('gaussian', 545.5594781168514, 0.01),\n",
       " ('gaussian', 545.5594781168514, 0.027825594022071243),\n",
       " ('gaussian', 545.5594781168514, 0.0774263682681127),\n",
       " ('gaussian', 545.5594781168514, 0.21544346900318834),\n",
       " ('gaussian', 545.5594781168514, 0.5994842503189409),\n",
       " ('gaussian', 545.5594781168514, 1.6681005372000592),\n",
       " ('gaussian', 545.5594781168514, 4.6415888336127775),\n",
       " ('gaussian', 545.5594781168514, 12.915496650148826),\n",
       " ('gaussian', 545.5594781168514, 35.93813663804626),\n",
       " ('gaussian', 545.5594781168514, 100.0),\n",
       " ('gaussian', 1438.44988828766, 0.01),\n",
       " ('gaussian', 1438.44988828766, 0.027825594022071243),\n",
       " ('gaussian', 1438.44988828766, 0.0774263682681127),\n",
       " ('gaussian', 1438.44988828766, 0.21544346900318834),\n",
       " ('gaussian', 1438.44988828766, 0.5994842503189409),\n",
       " ('gaussian', 1438.44988828766, 1.6681005372000592),\n",
       " ('gaussian', 1438.44988828766, 4.6415888336127775),\n",
       " ('gaussian', 1438.44988828766, 12.915496650148826),\n",
       " ('gaussian', 1438.44988828766, 35.93813663804626),\n",
       " ('gaussian', 1438.44988828766, 100.0),\n",
       " ('gaussian', 3792.690190732246, 0.01),\n",
       " ('gaussian', 3792.690190732246, 0.027825594022071243),\n",
       " ('gaussian', 3792.690190732246, 0.0774263682681127),\n",
       " ('gaussian', 3792.690190732246, 0.21544346900318834),\n",
       " ('gaussian', 3792.690190732246, 0.5994842503189409),\n",
       " ('gaussian', 3792.690190732246, 1.6681005372000592),\n",
       " ('gaussian', 3792.690190732246, 4.6415888336127775),\n",
       " ('gaussian', 3792.690190732246, 12.915496650148826),\n",
       " ('gaussian', 3792.690190732246, 35.93813663804626),\n",
       " ('gaussian', 3792.690190732246, 100.0),\n",
       " ('gaussian', 10000.0, 0.01),\n",
       " ('gaussian', 10000.0, 0.027825594022071243),\n",
       " ('gaussian', 10000.0, 0.0774263682681127),\n",
       " ('gaussian', 10000.0, 0.21544346900318834),\n",
       " ('gaussian', 10000.0, 0.5994842503189409),\n",
       " ('gaussian', 10000.0, 1.6681005372000592),\n",
       " ('gaussian', 10000.0, 4.6415888336127775),\n",
       " ('gaussian', 10000.0, 12.915496650148826),\n",
       " ('gaussian', 10000.0, 35.93813663804626),\n",
       " ('gaussian', 10000.0, 100.0)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(itertools.product(*params['alpha'].values(), *params['kernel']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
