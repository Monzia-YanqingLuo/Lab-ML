{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "import itertools as it\n",
    "import time\n",
    "import pylab as pl\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.a loss function `mean_absolute_error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(y_true, y_pred):\n",
    "    ''' your code here '''\n",
    "    if not isinstance(y_true,np.ndarray) and isinstance(y_pred, np.ndarray):\n",
    "        print(f\"Both inputs must be np-array.\")\n",
    "        \n",
    "    return sum(abs(y_true - y_pred)) / len(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b Cross-Validation function `cv`\n",
    "Inputs:\n",
    "- X: matrix\n",
    "- y: vertor\n",
    "- method: object\n",
    "- parameters: dictionary\n",
    "- loss_function: function\n",
    "- nfolds: int\n",
    "- nrepetitions: int\n",
    "\n",
    "Output: `method` object includs functions `fit(X, y)` and `predict(X)`\n",
    "- Output is a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisysincfunction(N, noise):\n",
    "    ''' noisysincfunction - generate data from the \"noisy sinc function\"\n",
    "        % usage\n",
    "        %     [X, Y] = noisysincfunction(N, noise)\n",
    "        %\n",
    "        % input\n",
    "        %     N: number of data points\n",
    "        %     noise: standard variation of the noise\n",
    "        %\n",
    "        % output\n",
    "        %     X: (1, N)-matrix uniformly sampled in -2pi, pi\n",
    "        %     Y: (1, N)-matrix equal to sinc(X) + noise\n",
    "        %\n",
    "        % description\n",
    "        %     Generates N points from the noisy sinc function\n",
    "        %\n",
    "        %        X ~ uniformly in [-2pi, pi]\n",
    "        %        Y = sinc(X) + eps, eps ~ Normal(0, noise.^2)\n",
    "        %\n",
    "        % author\n",
    "        %     Mikio Braun\n",
    "    '''\n",
    "    X = np.sort(2 * np.pi * np.random.rand(1, N) ) - np.pi\n",
    "    Y = np.sinc(X) + noise * np.random.randn(1, N)\n",
    "    return X.reshape(-1, 1), Y.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "TRAIN: [4 2 5 8 6 3] TEST: [7 0 1]\n",
      "Fold 2\n",
      "TRAIN: [7 0 1 8 6 3] TEST: [4 2 5]\n",
      "Fold 3\n",
      "TRAIN: [7 0 1 4 2 5] TEST: [8 6 3]\n"
     ]
    }
   ],
   "source": [
    "class KFold:\n",
    "    def __init__(self, n_splits=5):\n",
    "        self.n_splits = n_splits\n",
    "\n",
    "    def split(self, X):\n",
    "        n_samples = len(X)\n",
    "        indices = np.arange(n_samples)\n",
    "\n",
    "        rng = np.random.default_rng(True)\n",
    "        rng.shuffle(indices)\n",
    "        \n",
    "        fold_sizes = np.full(self.n_splits, n_samples // self.n_splits, dtype=int)\n",
    "        fold_sizes[:n_samples % self.n_splits] += 1\n",
    "        current = 0\n",
    "        splits = []\n",
    "        \n",
    "        for fold_size in fold_sizes:\n",
    "            start, stop = current, current + fold_size\n",
    "            test_idx = indices[start:stop]\n",
    "            train_idx = np.concatenate((indices[:start], indices[stop:]))\n",
    "            splits.append((train_idx, test_idx))\n",
    "            current = stop\n",
    "        \n",
    "        return splits\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "X = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "splits = kf.split(X)\n",
    "for i, (train_index, test_index) in enumerate(splits):\n",
    "    print(f\"Fold {i + 1}\")\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "def cv(X, y, method, params, loss_function=mean_absolute_error, nfolds=10, nrepetitions=5):\n",
    "    ''' your header here!\n",
    "    '''\n",
    "    best_loss = float('inf')\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    kf = KFold(n_splits=nfolds)\n",
    "    \n",
    "    # all_param_combinations = list(itertools.product(*parameters.values()))\n",
    "    \n",
    "    # all_param_combinations = np.array(list(itertools.product(params['regularization'], params['kernel'])))\n",
    "    param_keys = list(params.keys())\n",
    "    all_param_combinations = list(itertools.product(*(params[key] for key in param_keys)))\n",
    "    \n",
    "    total_iterations = len(all_param_combinations) * nrepetitions * nfolds\n",
    "    iteration = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for param_combination in all_param_combinations:\n",
    "        # param_dict = dict(zip(['regularization', 'kernel'], param_combination))\n",
    "        # param_dict['kernelparameter'] = params['kernelparameter']\n",
    "        param_dict = dict(zip(param_keys, param_combination))\n",
    "\n",
    "\n",
    "        total_loss = 0\n",
    "        \n",
    "        for _ in range(nrepetitions):\n",
    "            fold_losses = []\n",
    "            for train_index, val_index in kf.split(X):\n",
    "                X_train, X_val = X[train_index], X[val_index]\n",
    "                y_train, y_val = y[train_index], y[val_index]\n",
    "                \n",
    "                model = method(**param_dict)\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_val)\n",
    "                \n",
    "                fold_loss = loss_function(y_val, y_pred)\n",
    "                fold_losses.append(fold_loss)\n",
    "\n",
    "                # Update iteration and report progress\n",
    "                iteration += 1\n",
    "                elapsed_time = time.time() - start_time\n",
    "                remaining_time = (elapsed_time / iteration) * (total_iterations - iteration)\n",
    "                print(f'Progress: {iteration}/{total_iterations} - '\n",
    "                      f'Elapsed Time: {elapsed_time:.2f}s - '\n",
    "                      f'Remaining Time: {remaining_time:.2f}s', end='\\r')\n",
    "                \n",
    "            total_loss += np.mean(fold_losses)\n",
    "        \n",
    "        avg_loss = total_loss / nrepetitions\n",
    "        \n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            best_params = param_dict\n",
    "            best_model = method(**best_params)\n",
    "            best_model.fit(X, y)\n",
    "    \n",
    "    best_model.cvloss = best_loss\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class krr():\n",
    "    ''' Kernel Ridge Regression (KRR) implements ridge regression with various kernel functions.\n",
    "        This class allows specification of the kernel type, kernel parameters, and regularization strength.\n",
    "    '''\n",
    "    def __init__(self, kernel='linear', kernelparameter=1, regularization=0):\n",
    "        self.kernel = kernel\n",
    "        self.kernelparameter = kernelparameter\n",
    "        self.regularization = regularization\n",
    "        self.alpha = None  # Coefficient matrix for predictions\n",
    "        self.X_train = None  # Store training features here\n",
    "    \n",
    "    def _compute_kernel(self, X1, X2):\n",
    "        ''' Compute the kernel matrix between datasets X1 and X2 based on the specified kernel type. '''\n",
    "        if self.kernel == 'linear':\n",
    "            return np.dot(X1, X2.T)\n",
    "        elif self.kernel == 'polynomial':\n",
    "            return (np.dot(X1, X2.T) + 1) ** self.kernelparameter\n",
    "        elif self.kernel == 'gaussian':\n",
    "            sq_dists = np.sum(X1**2, axis=1).reshape(-1, 1) + np.sum(X2**2, axis=1) - 2 * np.dot(X1, X2.T)\n",
    "            return np.exp(-0.5 / self.kernelparameter**2 * sq_dists)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported kernel type\")\n",
    "\n",
    "    def fit(self, X, y, kernel=False, kernelparameter=False, regularization=False):\n",
    "        ''' Fit the KRR model using the provided training data and labels.\n",
    "            X: Feature matrix.\n",
    "            y: Target vector.\n",
    "            Optionally, kernel type, kernel parameter, and regularization can be adjusted.\n",
    "        '''\n",
    "        if kernel is not False:\n",
    "            self.kernel = kernel\n",
    "        if kernelparameter is not False:\n",
    "            self.kernelparameter = kernelparameter\n",
    "        if regularization is not False:\n",
    "            self.regularization = regularization\n",
    "        \n",
    "        self.X_train = X\n",
    "        n = X.shape[0]\n",
    "        K = self._compute_kernel(X, X)\n",
    "        I = np.eye(n)\n",
    "        self.alpha = np.linalg.inv(K + self.regularization * I) @ y\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        ''' Predicts the target values for given input features using the trained KRR model.\n",
    "            X: New feature matrix for which predictions are to be made.\n",
    "            Raises ValueError if the model has not been fitted.\n",
    "        '''\n",
    "        if self.X_train is None:\n",
    "            raise ValueError(\"Model has not been fitted yet. Please call 'fit' with appropriate data.\")\n",
    "        \n",
    "        K_new = self._compute_kernel(X, self.X_train)\n",
    "        return np.dot(K_new, self.alpha)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization range: 10**-4 .. 10**4.43s - Remaining Time: 0.00s\n",
      "Gaussian kernel parameter:  0.0001\n",
      "Regularization paramter:  100.0\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "Xtr, Ytr = noisysincfunction(100, 0.1)\n",
    "Xte = np.arange( -np.pi, np.pi, 0.01 ).reshape(-1, 1)\n",
    "\n",
    "params = { 'kernel': ['linear'], 'kernelparameter': np.logspace(-4,4,20),\n",
    "                'regularization': np.logspace(-2,2,10) }\n",
    "cvkrr = cv(Xtr, Ytr, krr, params, nrepetitions=2)\n",
    "ypred = cvkrr.predict(Xte)\n",
    "print('Regularization range: 10**-4 .. 10**4')\n",
    "print('Gaussian kernel parameter: ', cvkrr.kernelparameter)\n",
    "print('Regularization paramter: ', cvkrr.regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'gaussian', 'alpha': '0.01'}\n",
      "{'kernel': 'gaussian', 'alpha': '0.027825594022071243'}\n",
      "{'kernel': 'gaussian', 'alpha': '0.0774263682681127'}\n",
      "{'kernel': 'gaussian', 'alpha': '0.21544346900318834'}\n",
      "{'kernel': 'gaussian', 'alpha': '0.5994842503189409'}\n",
      "{'kernel': 'gaussian', 'alpha': '1.6681005372000592'}\n",
      "{'kernel': 'gaussian', 'alpha': '4.6415888336127775'}\n",
      "{'kernel': 'gaussian', 'alpha': '12.915496650148826'}\n",
      "{'kernel': 'gaussian', 'alpha': '35.93813663804626'}\n",
      "{'kernel': 'gaussian', 'alpha': '100.0'}\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "params = { 'kernel': ['gaussian'], 'kernelparameter': np.logspace(-4,4,20),\n",
    "        'alpha': np.logspace(-2,2,10) }\n",
    "\n",
    "all_param_combinations = np.array(list(itertools.product(params['kernel'], params['alpha'])))\n",
    "# all_param_combinations + params['kernelparameter']\n",
    "for param_combination in all_param_combinations:\n",
    "        param_dict = dict(zip(['kernel', 'alpha'], param_combination))\n",
    "        print(param_dict)\n",
    "        param_dict['kernelparameter'] = params['kernelparameter']\n",
    "        \n",
    "        total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gaussian', 0.0001, 0.01),\n",
       " ('gaussian', 0.0001, 0.027825594022071243),\n",
       " ('gaussian', 0.0001, 0.0774263682681127),\n",
       " ('gaussian', 0.0001, 0.21544346900318834),\n",
       " ('gaussian', 0.0001, 0.5994842503189409),\n",
       " ('gaussian', 0.0001, 1.6681005372000592),\n",
       " ('gaussian', 0.0001, 4.6415888336127775),\n",
       " ('gaussian', 0.0001, 12.915496650148826),\n",
       " ('gaussian', 0.0001, 35.93813663804626),\n",
       " ('gaussian', 0.0001, 100.0),\n",
       " ('gaussian', 0.00026366508987303583, 0.01),\n",
       " ('gaussian', 0.00026366508987303583, 0.027825594022071243),\n",
       " ('gaussian', 0.00026366508987303583, 0.0774263682681127),\n",
       " ('gaussian', 0.00026366508987303583, 0.21544346900318834),\n",
       " ('gaussian', 0.00026366508987303583, 0.5994842503189409),\n",
       " ('gaussian', 0.00026366508987303583, 1.6681005372000592),\n",
       " ('gaussian', 0.00026366508987303583, 4.6415888336127775),\n",
       " ('gaussian', 0.00026366508987303583, 12.915496650148826),\n",
       " ('gaussian', 0.00026366508987303583, 35.93813663804626),\n",
       " ('gaussian', 0.00026366508987303583, 100.0),\n",
       " ('gaussian', 0.0006951927961775605, 0.01),\n",
       " ('gaussian', 0.0006951927961775605, 0.027825594022071243),\n",
       " ('gaussian', 0.0006951927961775605, 0.0774263682681127),\n",
       " ('gaussian', 0.0006951927961775605, 0.21544346900318834),\n",
       " ('gaussian', 0.0006951927961775605, 0.5994842503189409),\n",
       " ('gaussian', 0.0006951927961775605, 1.6681005372000592),\n",
       " ('gaussian', 0.0006951927961775605, 4.6415888336127775),\n",
       " ('gaussian', 0.0006951927961775605, 12.915496650148826),\n",
       " ('gaussian', 0.0006951927961775605, 35.93813663804626),\n",
       " ('gaussian', 0.0006951927961775605, 100.0),\n",
       " ('gaussian', 0.0018329807108324356, 0.01),\n",
       " ('gaussian', 0.0018329807108324356, 0.027825594022071243),\n",
       " ('gaussian', 0.0018329807108324356, 0.0774263682681127),\n",
       " ('gaussian', 0.0018329807108324356, 0.21544346900318834),\n",
       " ('gaussian', 0.0018329807108324356, 0.5994842503189409),\n",
       " ('gaussian', 0.0018329807108324356, 1.6681005372000592),\n",
       " ('gaussian', 0.0018329807108324356, 4.6415888336127775),\n",
       " ('gaussian', 0.0018329807108324356, 12.915496650148826),\n",
       " ('gaussian', 0.0018329807108324356, 35.93813663804626),\n",
       " ('gaussian', 0.0018329807108324356, 100.0),\n",
       " ('gaussian', 0.004832930238571752, 0.01),\n",
       " ('gaussian', 0.004832930238571752, 0.027825594022071243),\n",
       " ('gaussian', 0.004832930238571752, 0.0774263682681127),\n",
       " ('gaussian', 0.004832930238571752, 0.21544346900318834),\n",
       " ('gaussian', 0.004832930238571752, 0.5994842503189409),\n",
       " ('gaussian', 0.004832930238571752, 1.6681005372000592),\n",
       " ('gaussian', 0.004832930238571752, 4.6415888336127775),\n",
       " ('gaussian', 0.004832930238571752, 12.915496650148826),\n",
       " ('gaussian', 0.004832930238571752, 35.93813663804626),\n",
       " ('gaussian', 0.004832930238571752, 100.0),\n",
       " ('gaussian', 0.012742749857031334, 0.01),\n",
       " ('gaussian', 0.012742749857031334, 0.027825594022071243),\n",
       " ('gaussian', 0.012742749857031334, 0.0774263682681127),\n",
       " ('gaussian', 0.012742749857031334, 0.21544346900318834),\n",
       " ('gaussian', 0.012742749857031334, 0.5994842503189409),\n",
       " ('gaussian', 0.012742749857031334, 1.6681005372000592),\n",
       " ('gaussian', 0.012742749857031334, 4.6415888336127775),\n",
       " ('gaussian', 0.012742749857031334, 12.915496650148826),\n",
       " ('gaussian', 0.012742749857031334, 35.93813663804626),\n",
       " ('gaussian', 0.012742749857031334, 100.0),\n",
       " ('gaussian', 0.03359818286283781, 0.01),\n",
       " ('gaussian', 0.03359818286283781, 0.027825594022071243),\n",
       " ('gaussian', 0.03359818286283781, 0.0774263682681127),\n",
       " ('gaussian', 0.03359818286283781, 0.21544346900318834),\n",
       " ('gaussian', 0.03359818286283781, 0.5994842503189409),\n",
       " ('gaussian', 0.03359818286283781, 1.6681005372000592),\n",
       " ('gaussian', 0.03359818286283781, 4.6415888336127775),\n",
       " ('gaussian', 0.03359818286283781, 12.915496650148826),\n",
       " ('gaussian', 0.03359818286283781, 35.93813663804626),\n",
       " ('gaussian', 0.03359818286283781, 100.0),\n",
       " ('gaussian', 0.08858667904100823, 0.01),\n",
       " ('gaussian', 0.08858667904100823, 0.027825594022071243),\n",
       " ('gaussian', 0.08858667904100823, 0.0774263682681127),\n",
       " ('gaussian', 0.08858667904100823, 0.21544346900318834),\n",
       " ('gaussian', 0.08858667904100823, 0.5994842503189409),\n",
       " ('gaussian', 0.08858667904100823, 1.6681005372000592),\n",
       " ('gaussian', 0.08858667904100823, 4.6415888336127775),\n",
       " ('gaussian', 0.08858667904100823, 12.915496650148826),\n",
       " ('gaussian', 0.08858667904100823, 35.93813663804626),\n",
       " ('gaussian', 0.08858667904100823, 100.0),\n",
       " ('gaussian', 0.23357214690901212, 0.01),\n",
       " ('gaussian', 0.23357214690901212, 0.027825594022071243),\n",
       " ('gaussian', 0.23357214690901212, 0.0774263682681127),\n",
       " ('gaussian', 0.23357214690901212, 0.21544346900318834),\n",
       " ('gaussian', 0.23357214690901212, 0.5994842503189409),\n",
       " ('gaussian', 0.23357214690901212, 1.6681005372000592),\n",
       " ('gaussian', 0.23357214690901212, 4.6415888336127775),\n",
       " ('gaussian', 0.23357214690901212, 12.915496650148826),\n",
       " ('gaussian', 0.23357214690901212, 35.93813663804626),\n",
       " ('gaussian', 0.23357214690901212, 100.0),\n",
       " ('gaussian', 0.615848211066026, 0.01),\n",
       " ('gaussian', 0.615848211066026, 0.027825594022071243),\n",
       " ('gaussian', 0.615848211066026, 0.0774263682681127),\n",
       " ('gaussian', 0.615848211066026, 0.21544346900318834),\n",
       " ('gaussian', 0.615848211066026, 0.5994842503189409),\n",
       " ('gaussian', 0.615848211066026, 1.6681005372000592),\n",
       " ('gaussian', 0.615848211066026, 4.6415888336127775),\n",
       " ('gaussian', 0.615848211066026, 12.915496650148826),\n",
       " ('gaussian', 0.615848211066026, 35.93813663804626),\n",
       " ('gaussian', 0.615848211066026, 100.0),\n",
       " ('gaussian', 1.623776739188721, 0.01),\n",
       " ('gaussian', 1.623776739188721, 0.027825594022071243),\n",
       " ('gaussian', 1.623776739188721, 0.0774263682681127),\n",
       " ('gaussian', 1.623776739188721, 0.21544346900318834),\n",
       " ('gaussian', 1.623776739188721, 0.5994842503189409),\n",
       " ('gaussian', 1.623776739188721, 1.6681005372000592),\n",
       " ('gaussian', 1.623776739188721, 4.6415888336127775),\n",
       " ('gaussian', 1.623776739188721, 12.915496650148826),\n",
       " ('gaussian', 1.623776739188721, 35.93813663804626),\n",
       " ('gaussian', 1.623776739188721, 100.0),\n",
       " ('gaussian', 4.281332398719396, 0.01),\n",
       " ('gaussian', 4.281332398719396, 0.027825594022071243),\n",
       " ('gaussian', 4.281332398719396, 0.0774263682681127),\n",
       " ('gaussian', 4.281332398719396, 0.21544346900318834),\n",
       " ('gaussian', 4.281332398719396, 0.5994842503189409),\n",
       " ('gaussian', 4.281332398719396, 1.6681005372000592),\n",
       " ('gaussian', 4.281332398719396, 4.6415888336127775),\n",
       " ('gaussian', 4.281332398719396, 12.915496650148826),\n",
       " ('gaussian', 4.281332398719396, 35.93813663804626),\n",
       " ('gaussian', 4.281332398719396, 100.0),\n",
       " ('gaussian', 11.288378916846883, 0.01),\n",
       " ('gaussian', 11.288378916846883, 0.027825594022071243),\n",
       " ('gaussian', 11.288378916846883, 0.0774263682681127),\n",
       " ('gaussian', 11.288378916846883, 0.21544346900318834),\n",
       " ('gaussian', 11.288378916846883, 0.5994842503189409),\n",
       " ('gaussian', 11.288378916846883, 1.6681005372000592),\n",
       " ('gaussian', 11.288378916846883, 4.6415888336127775),\n",
       " ('gaussian', 11.288378916846883, 12.915496650148826),\n",
       " ('gaussian', 11.288378916846883, 35.93813663804626),\n",
       " ('gaussian', 11.288378916846883, 100.0),\n",
       " ('gaussian', 29.763514416313132, 0.01),\n",
       " ('gaussian', 29.763514416313132, 0.027825594022071243),\n",
       " ('gaussian', 29.763514416313132, 0.0774263682681127),\n",
       " ('gaussian', 29.763514416313132, 0.21544346900318834),\n",
       " ('gaussian', 29.763514416313132, 0.5994842503189409),\n",
       " ('gaussian', 29.763514416313132, 1.6681005372000592),\n",
       " ('gaussian', 29.763514416313132, 4.6415888336127775),\n",
       " ('gaussian', 29.763514416313132, 12.915496650148826),\n",
       " ('gaussian', 29.763514416313132, 35.93813663804626),\n",
       " ('gaussian', 29.763514416313132, 100.0),\n",
       " ('gaussian', 78.47599703514607, 0.01),\n",
       " ('gaussian', 78.47599703514607, 0.027825594022071243),\n",
       " ('gaussian', 78.47599703514607, 0.0774263682681127),\n",
       " ('gaussian', 78.47599703514607, 0.21544346900318834),\n",
       " ('gaussian', 78.47599703514607, 0.5994842503189409),\n",
       " ('gaussian', 78.47599703514607, 1.6681005372000592),\n",
       " ('gaussian', 78.47599703514607, 4.6415888336127775),\n",
       " ('gaussian', 78.47599703514607, 12.915496650148826),\n",
       " ('gaussian', 78.47599703514607, 35.93813663804626),\n",
       " ('gaussian', 78.47599703514607, 100.0),\n",
       " ('gaussian', 206.913808111479, 0.01),\n",
       " ('gaussian', 206.913808111479, 0.027825594022071243),\n",
       " ('gaussian', 206.913808111479, 0.0774263682681127),\n",
       " ('gaussian', 206.913808111479, 0.21544346900318834),\n",
       " ('gaussian', 206.913808111479, 0.5994842503189409),\n",
       " ('gaussian', 206.913808111479, 1.6681005372000592),\n",
       " ('gaussian', 206.913808111479, 4.6415888336127775),\n",
       " ('gaussian', 206.913808111479, 12.915496650148826),\n",
       " ('gaussian', 206.913808111479, 35.93813663804626),\n",
       " ('gaussian', 206.913808111479, 100.0),\n",
       " ('gaussian', 545.5594781168514, 0.01),\n",
       " ('gaussian', 545.5594781168514, 0.027825594022071243),\n",
       " ('gaussian', 545.5594781168514, 0.0774263682681127),\n",
       " ('gaussian', 545.5594781168514, 0.21544346900318834),\n",
       " ('gaussian', 545.5594781168514, 0.5994842503189409),\n",
       " ('gaussian', 545.5594781168514, 1.6681005372000592),\n",
       " ('gaussian', 545.5594781168514, 4.6415888336127775),\n",
       " ('gaussian', 545.5594781168514, 12.915496650148826),\n",
       " ('gaussian', 545.5594781168514, 35.93813663804626),\n",
       " ('gaussian', 545.5594781168514, 100.0),\n",
       " ('gaussian', 1438.44988828766, 0.01),\n",
       " ('gaussian', 1438.44988828766, 0.027825594022071243),\n",
       " ('gaussian', 1438.44988828766, 0.0774263682681127),\n",
       " ('gaussian', 1438.44988828766, 0.21544346900318834),\n",
       " ('gaussian', 1438.44988828766, 0.5994842503189409),\n",
       " ('gaussian', 1438.44988828766, 1.6681005372000592),\n",
       " ('gaussian', 1438.44988828766, 4.6415888336127775),\n",
       " ('gaussian', 1438.44988828766, 12.915496650148826),\n",
       " ('gaussian', 1438.44988828766, 35.93813663804626),\n",
       " ('gaussian', 1438.44988828766, 100.0),\n",
       " ('gaussian', 3792.690190732246, 0.01),\n",
       " ('gaussian', 3792.690190732246, 0.027825594022071243),\n",
       " ('gaussian', 3792.690190732246, 0.0774263682681127),\n",
       " ('gaussian', 3792.690190732246, 0.21544346900318834),\n",
       " ('gaussian', 3792.690190732246, 0.5994842503189409),\n",
       " ('gaussian', 3792.690190732246, 1.6681005372000592),\n",
       " ('gaussian', 3792.690190732246, 4.6415888336127775),\n",
       " ('gaussian', 3792.690190732246, 12.915496650148826),\n",
       " ('gaussian', 3792.690190732246, 35.93813663804626),\n",
       " ('gaussian', 3792.690190732246, 100.0),\n",
       " ('gaussian', 10000.0, 0.01),\n",
       " ('gaussian', 10000.0, 0.027825594022071243),\n",
       " ('gaussian', 10000.0, 0.0774263682681127),\n",
       " ('gaussian', 10000.0, 0.21544346900318834),\n",
       " ('gaussian', 10000.0, 0.5994842503189409),\n",
       " ('gaussian', 10000.0, 1.6681005372000592),\n",
       " ('gaussian', 10000.0, 4.6415888336127775),\n",
       " ('gaussian', 10000.0, 12.915496650148826),\n",
       " ('gaussian', 10000.0, 35.93813663804626),\n",
       " ('gaussian', 10000.0, 100.0)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(itertools.product(*params['alpha'].values(), *params['kernel']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
